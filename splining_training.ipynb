{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f04ce239-1b62-432e-b8db-d41571823834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ase.io\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import functools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a85135d-1f44-406e-be0d-4409afe857eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = ase.io.read('./gp_iter6_sparse9k.xml.xyz', ':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c41d28-21f3-4ad0-a75d-9e2399ca00c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2475\n"
     ]
    }
   ],
   "source": [
    "print(len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbebb8a6-e90f-4981-b734-bb6ed3d7f0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2475\n"
     ]
    }
   ],
   "source": [
    "frames = [frame for frame in frames if ('dft_energy' in frame.info.keys()) or ('DFT_energy' in frame.info.keys())]\n",
    "print(len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fcf002b-7aee-4503-833f-66511cd8f1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2475"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dressed_energies_per_atom = []\n",
    "# energy of one isolated Si atom\n",
    "baseline_energy = frames[0].info['dft_energy'] \n",
    "for frame in frames:\n",
    "    energy = frame.info['dft_energy'] if ('dft_energy' in frame.info.keys()) else frame.info['DFT_energy']\n",
    "    frame.info['energy'] = energy\n",
    "    energy -= baseline_energy*len(frame)\n",
    "    frame.info['dressed_energy'] = energy\n",
    "    energy /= len(frame)\n",
    "    frame.info['dressed_energy_per_atom'] = energy\n",
    "    dressed_energies_per_atom.append( energy )\n",
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2f2b6bb-f4f9-4fe3-9789-782f1fd31bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dressed_energies_per_atom = np.array(dressed_energies_per_atom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6ef0c8-9e2e-4007-9e28-65762a31e673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dressed_energies_per_atom)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e4f98e6-7317-4183-9546-2ec4abc413c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_std=False).fit(dressed_energies_per_atom.reshape(-1,1))\n",
    "scaled_dressed_energies_per_atom = scaler.transform(dressed_energies_per_atom.reshape(-1,1)).reshape(-1)\n",
    "for i, frame in enumerate(frames):\n",
    "    frame.info['scaled_dressed_energies_per_atom'] = scaled_dressed_energies_per_atom[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "045189e9-104e-49ea-851d-6f221de79037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(scaled_dressed_energies_per_atom)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c26dae-93a7-48f3-9f58-b7d4886ac266",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08ff2455-9c28-479e-a72f-74cf692dccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Dict, List, Tuple, TypeVar, Callable, Optional\n",
    "import ase\n",
    "\n",
    "import abc\n",
    "AtomicStructure = TypeVar('AtomicStructure')\n",
    "\n",
    "def structure_to_torch(structure : AtomicStructure,\n",
    "        device : Optional[torch.device] = None,\n",
    "        dtype: Optional[torch.dtype] = None) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    :returns:\n",
    "        Tuple of posititions, species, cell and periodic boundary conditions\n",
    "    \"\"\"\n",
    "    if isinstance(structure, ase.Atoms):\n",
    "        # dtype is automatically referred from the type in the structure object if None\n",
    "        positions = torch.tensor(structure.positions, device=device, dtype=dtype)\n",
    "        species = torch.tensor(structure.numbers, device=device)\n",
    "        cell = torch.tensor(structure.cell.array, device=device, dtype=dtype)\n",
    "        pbc = torch.tensor(structure.pbc, device=device)\n",
    "        return positions, species, cell, pbc\n",
    "    else:\n",
    "        raise ValueError(\"Unknown atom type. We only support ase.Atoms at the moment.\")\n",
    "\n",
    "def build_neighborlist(positions: torch.Tensor, cell: torch.Tensor, pbc: torch.Tensor, cutoff : float) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "\n",
    "    assert positions.device == cell.device\n",
    "    assert positions.device == pbc.device\n",
    "    device = positions.device\n",
    "\n",
    "    # will be replaced with something with GPU support\n",
    "    pairs_i, pairs_j, cell_shifts = ase.neighborlist.primitive_neighbor_list(\n",
    "        quantities=\"ijS\",\n",
    "        positions=positions.detach().cpu().numpy(),\n",
    "        cell=cell.detach().cpu().numpy(),\n",
    "        pbc=pbc.detach().cpu().numpy(),\n",
    "        cutoff=cutoff,\n",
    "        self_interaction=False,\n",
    "        use_scaled_positions=False,\n",
    "    )\n",
    "    pairs_i = torch.tensor(pairs_i, device=device)\n",
    "    pairs_j = torch.tensor(pairs_j, device=device)\n",
    "    cell_shifts = torch.tensor(cell_shifts, device=device)\n",
    "\n",
    "    pairs = torch.vstack([pairs_i, pairs_j]).T\n",
    "    centers = torch.arange(len(positions), device=device)\n",
    "    return centers, pairs, cell_shifts\n",
    "\n",
    "\n",
    "class TransformerBase(metaclass=abc.ABCMeta):\n",
    "    \"\"\"\n",
    "    Abstract class for extracting information of an AtomicStructure objects and processing it\n",
    "    \"\"\"\n",
    "    @abc.abstractmethod\n",
    "    def __call__(self, structure: AtomicStructure) -> Dict[str, torch.Tensor]:\n",
    "        pass\n",
    "\n",
    "class TransformerProperty(TransformerBase):\n",
    "    \"\"\"\n",
    "    Extracts property information out of an AtomicStructure using a function given as input\n",
    "    \"\"\"\n",
    "    def __init__(self, property_name: List[str], get_property: List[Callable[[AtomicStructure], torch.Tensor]],\n",
    "            device=None, dtype=None):\n",
    "        if not(isinstance(get_property, list)):\n",
    "            property_name = [property_name]\n",
    "        if not(isinstance (get_property, list)):\n",
    "            get_property = [get_property]\n",
    "        self._get_property = get_property\n",
    "        self._property_name = property_name\n",
    "        self._device = device\n",
    "        self._dtype = dtype\n",
    "\n",
    "\n",
    "    def __call__(self, structure: AtomicStructure) -> Dict[str, torch.Tensor]:\n",
    "        return {self._property_name[i]: self._get_property[i](structure).to(device=self._device, dtype=self._dtype)\n",
    "                for i in range(len(self._property_name))}\n",
    "\n",
    "class TransformerNeighborList(TransformerBase):\n",
    "    \"\"\"\n",
    "    Produces a neighbour list and with direction vectors from an AtomicStructure\n",
    "    \"\"\"\n",
    "    def __init__(self, cutoff: float, device=None, dtype=None):\n",
    "        self._cutoff = cutoff\n",
    "        self._device = device\n",
    "        self._dtype = dtype\n",
    "\n",
    "    def __call__(self, structure: AtomicStructure) -> Dict[str, torch.Tensor]:\n",
    "        positions_i, species_i, cell_i, pbc_i = structure_to_torch(structure,\n",
    "                dtype=self._dtype, device=self._device)\n",
    "        centers_i, pairs_ij, cell_shifts_ij = build_neighborlist(positions_i, cell_i,\n",
    "                pbc_i, self._cutoff)\n",
    "\n",
    "        return {\n",
    "            'positions': positions_i,\n",
    "            'species': species_i,\n",
    "            'cell': cell_i,\n",
    "            'centers': centers_i,\n",
    "            'pairs': pairs_ij,\n",
    "            'cell_shifts': cell_shifts_ij\n",
    "        }\n",
    "\n",
    "# Temporary Dataset until we have an metatensor Dataset\n",
    "class InMemoryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 structures : List[AtomicStructure],\n",
    "                 transformers : List[TransformerBase]):\n",
    "        super().__init__()\n",
    "        self.n_structures = len(structures)\n",
    "        self._data = defaultdict(list)\n",
    "        for structure in structures:\n",
    "            for transformer in transformers:\n",
    "                data_i = transformer(structure)\n",
    "                for key in data_i.keys():\n",
    "                    self._data[key].append(data_i[key])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: self._data[key][idx] for key in self._data.keys()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_structures\n",
    "\n",
    "def collate_nl(data_list, device=None, dtype=None):\n",
    "\n",
    "    collated = {key: torch.concatenate([data[key].to(device=device) for data in data_list], dim=0)\n",
    "                for key in filter(lambda x : x not in [\"positions\", \"cell\"], data_list[0].keys())}\n",
    "    collated['positions'] = torch.concatenate([data[\"positions\"] for data in data_list]).to(dtype=dtype, device=device)\n",
    "    collated['cells'] = torch.stack([data[\"cell\"] for data in data_list]).to(dtype=dtype, device=device)\n",
    "    collated['structure_centers'] = torch.concatenate(\n",
    "        [torch.tensor([structure_index] * len(data_list[structure_index][\"centers\"]), dtype=torch.long, device=collated[\"positions\"].device) for structure_index in range(len(data_list))]\n",
    "    ).to(device=device)\n",
    "    collated['structure_pairs'] = torch.concatenate(\n",
    "        [torch.tensor([structure_index] * len(data_list[structure_index][\"pairs\"]), dtype=torch.long, device=collated[\"positions\"].device) for structure_index in range(len(data_list))]\n",
    "    ).to(device=device)\n",
    "    collated['structure_offsets'] = torch.tensor(\n",
    "        np.cumsum([0] + [structure_data[\"positions\"].shape[0] for structure_data in data_list[:-1]]),\n",
    "        device=collated[\"positions\"][0].device,\n",
    "        dtype=torch.long\n",
    "    ).to(device=device)\n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "956ef021-2550-4ffa-9a90-4de56818260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTOFF = 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0f019ad-d841-46a2-baff-fa5bdcd3d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dressed_energy_per_atom(frame) -> torch.Tensor:\n",
    "    return torch.tensor([frame.info['scaled_dressed_energies_per_atom']])\n",
    "    \n",
    "dataset = InMemoryDataset(frames[:200],\n",
    "                          [TransformerNeighborList(cutoff=CUTOFF),\n",
    "                           TransformerProperty(\"scaled_dressed_energies_per_atom\", get_dressed_energy_per_atom)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85bf7e54-d72a-4af2-b056-336458e491ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, collate_fn=collate_nl, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "898093e7-9151-45cc-b683-561049ef5aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'species': tensor([14, 14]),\n",
       " 'centers': tensor([0, 0]),\n",
       " 'pairs': tensor([[0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0]]),\n",
       " 'cell_shifts': tensor([[ 2,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         [ 0,  1,  1],\n",
       "         [-1,  1,  1],\n",
       "         [ 1,  0,  1],\n",
       "         [ 0,  0,  1],\n",
       "         [-1,  0,  1],\n",
       "         [ 0,  2,  1],\n",
       "         [ 1,  2,  1],\n",
       "         [ 1, -1,  1],\n",
       "         [ 0, -1,  1],\n",
       "         [ 2,  2,  0],\n",
       "         [ 1,  2,  0],\n",
       "         [ 0,  2,  0],\n",
       "         [ 2,  1,  0],\n",
       "         [ 1,  1,  0],\n",
       "         [ 0,  1,  0],\n",
       "         [-1,  1,  0],\n",
       "         [-1, -1,  1],\n",
       "         [-2, -1,  1],\n",
       "         [ 0, -2,  1],\n",
       "         [-1, -2,  1],\n",
       "         [ 2,  0,  0],\n",
       "         [ 1,  0,  2],\n",
       "         [ 0,  0,  2],\n",
       "         [-1,  0,  2],\n",
       "         [ 0, -1,  2],\n",
       "         [-1, -1,  2],\n",
       "         [ 0,  1,  2],\n",
       "         [ 1,  1,  2],\n",
       "         [ 1,  0,  0],\n",
       "         [-1,  0,  0],\n",
       "         [-2,  0,  0],\n",
       "         [ 1,  1, -2],\n",
       "         [ 0,  1, -2],\n",
       "         [ 1,  0, -2],\n",
       "         [-1,  0, -2],\n",
       "         [ 0, -1, -2],\n",
       "         [-1, -1, -2],\n",
       "         [ 0,  0, -2],\n",
       "         [ 1,  2, -1],\n",
       "         [ 0,  2, -1],\n",
       "         [ 2,  1, -1],\n",
       "         [ 1,  1, -1],\n",
       "         [ 1, -1,  0],\n",
       "         [ 0, -1,  0],\n",
       "         [-1, -1,  0],\n",
       "         [-2, -1,  0],\n",
       "         [ 0,  1, -1],\n",
       "         [ 0, -2,  0],\n",
       "         [-1, -2,  0],\n",
       "         [-2, -2,  0],\n",
       "         [-1,  1, -1],\n",
       "         [-1, -2, -1],\n",
       "         [ 1,  0, -1],\n",
       "         [ 0,  0, -1],\n",
       "         [-1,  0, -1],\n",
       "         [ 0, -1, -1],\n",
       "         [-1, -1, -1],\n",
       "         [-2, -1, -1],\n",
       "         [ 0, -2, -1],\n",
       "         [ 1, -1, -1]]),\n",
       " 'scaled_dressed_energies_per_atom': tensor([ 4.1805, -0.0564], dtype=torch.float64),\n",
       " 'positions': tensor([[10., 10., 10.],\n",
       "         [ 0.,  0.,  0.]], dtype=torch.float64),\n",
       " 'cells': tensor([[[20.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000, 20.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, 20.0000]],\n",
       " \n",
       "         [[ 2.8355,  0.0000,  0.0000],\n",
       "          [-1.2374,  2.3493,  0.0000],\n",
       "          [-0.0802, -0.0871,  2.4470]]], dtype=torch.float64),\n",
       " 'structure_centers': tensor([0, 1]),\n",
       " 'structure_pairs': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'structure_offsets': tensor([0, 1])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07be9653-9c76-4a05-bd81-8707fac2dab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import math\n",
    "\n",
    "class CosineCutoff(nn.Module):\n",
    "    r\"\"\" Behler-style cosine cutoff module.\n",
    "\n",
    "    .. math::\n",
    "       f(r) = \\begin{cases}\n",
    "        0.5 \\times \\left[1 + \\cos\\left(\\frac{\\pi r}{r_\\text{cutoff}}\\right)\\right]\n",
    "          & r < r_\\text{cutoff} \\\\\n",
    "        0 & r \\geqslant r_\\text{cutoff} \\\\\n",
    "        \\end{cases}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cutoff: float):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cutoff (float, optional): cutoff radius.\n",
    "        \"\"\"\n",
    "        super(CosineCutoff, self).__init__()\n",
    "        self.register_buffer(\"cutoff\", torch.FloatTensor([cutoff]))\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        return cosine_cutoff(input, self.cutoff)\n",
    "\n",
    "def cosine_cutoff(input: torch.Tensor, cutoff: torch.Tensor):\n",
    "    \"\"\" Behler-style cosine cutoff.\n",
    "\n",
    "        .. math::\n",
    "           f(r) = \\begin{cases}\n",
    "            0.5 \\times \\left[1 + \\cos\\left(\\frac{\\pi r}{r_\\text{cutoff}}\\right)\\right]\n",
    "              & r < r_\\text{cutoff} \\\\\n",
    "            0 & r \\geqslant r_\\text{cutoff} \\\\\n",
    "            \\end{cases}\n",
    "\n",
    "        Args:\n",
    "            cutoff (float, optional): cutoff radius.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    # Compute values of cutoff function\n",
    "    input_cut = 0.5 * (torch.cos(input * math.pi / cutoff) + 1.0)\n",
    "    # Remove contributions beyond the cutoff radius\n",
    "    input_cut *= (input < cutoff).float()\n",
    "    return input_cut\n",
    "\n",
    "\n",
    "class GaussianRBF(nn.Module):\n",
    "    r\"\"\"Gaussian radial basis functions.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, n_rbf: int, cutoff: float, start: float = 0.0, trainable: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_rbf: total number of Gaussian functions, :math:`N_g`.\n",
    "            cutoff: center of last Gaussian function, :math:`\\mu_{N_g}`\n",
    "            start: center of first Gaussian function, :math:`\\mu_0`.\n",
    "            trainable: If True, widths and offset of Gaussian functions\n",
    "                are adjusted during training process.\n",
    "        \"\"\"\n",
    "        super(GaussianRBF, self).__init__()\n",
    "        self.n_rbf = n_rbf\n",
    "\n",
    "        # compute offset and width of Gaussian functions\n",
    "        offset = torch.linspace(start, cutoff, n_rbf)\n",
    "        widths = torch.FloatTensor(\n",
    "            torch.abs(offset[1] - offset[0]) * torch.ones_like(offset)\n",
    "        )\n",
    "        if trainable:\n",
    "            self.widths = nn.Parameter(widths)\n",
    "            self.offsets = nn.Parameter(offset)\n",
    "        else:\n",
    "            self.register_buffer(\"widths\", widths)\n",
    "            self.register_buffer(\"offsets\", offset)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor):\n",
    "        return gaussian_rbf(inputs, self.offsets, self.widths)\n",
    "\n",
    "def gaussian_rbf(inputs: torch.Tensor, offsets: torch.Tensor, widths: torch.Tensor):\n",
    "    coeff = -0.5 / torch.pow(widths, 2)\n",
    "    diff = inputs[..., None] - offsets\n",
    "    y = torch.exp(coeff * torch.pow(diff, 2))\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3891bdd1-a7a2-4efa-9005-fb6b93376384",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cartesian_vectors(positions,\n",
    "                          cells, species, cell_shifts, centers, pairs, structure_centers, structure_pairs, structure_offsets):\n",
    "    \"\"\"\n",
    "    Wraps direction vectors into TensorBlock object with metadata information\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate interatomic vectors\n",
    "    pairs_offsets = structure_offsets[structure_pairs]\n",
    "    shifted_pairs = pairs_offsets[:, None] + pairs\n",
    "    shifted_pairs_i = shifted_pairs[:, 0]\n",
    "    shifted_pairs_j = shifted_pairs[:, 1]\n",
    "    direction_vectors = positions[shifted_pairs_j] - positions[shifted_pairs_i] + torch.einsum(\"ab, abc -> ac\", cell_shifts.to(cells.dtype), cells[structure_pairs])\n",
    "\n",
    "    # find associated metadata\n",
    "    #pairs_i = pairs[:, 0]\n",
    "    #pairs_j = pairs[:, 1]\n",
    "    #labels = torch.stack([\n",
    "    #    structure_pairs,\n",
    "    #    pairs_i,\n",
    "    #    pairs_j,\n",
    "    #    species[shifted_pairs_i],\n",
    "    #    species[shifted_pairs_j],\n",
    "    #    cell_shifts[:, 0],\n",
    "    #    cell_shifts[:, 1],\n",
    "    #    cell_shifts[:, 2]\n",
    "    #], dim=-1)\n",
    "    return direction_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c96352-df63-46df-9048-c877eb9ffef6",
   "metadata": {},
   "source": [
    "# Spliney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1298595c-0db5-4d57-87e5-8fcf8158c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class Spliney(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                cutoff: float,\n",
    "                feature_size: int = 128,\n",
    "                layers_per_interaction = 6,\n",
    "                self_interaction: int = 5,\n",
    "                neighbor_interaction: int = 0,\n",
    "                dtype = None,\n",
    "                device = None):\n",
    "        super().__init__()\n",
    "        self._feature_size = feature_size\n",
    "        self._layers_per_interaction = layers_per_interaction\n",
    "        self._self_interaction = self_interaction\n",
    "        self._neighbor_interaction = neighbor_interaction\n",
    "\n",
    "        self._embedding = torch.nn.Sequential(\n",
    "                            GaussianRBF(n_rbf=feature_size, cutoff=cutoff),\n",
    "                            CosineCutoff(cutoff)\n",
    "        )\n",
    "        self._embedding.to(device=device, dtype=dtype)\n",
    "        self._layer = torch.nn.Sequential(\n",
    "                        torch.nn.Linear(self._feature_size, self._feature_size, dtype=dtype, device=device),\n",
    "                        torch.nn.SiLU())\n",
    "        # TODO rename to input_layers\n",
    "        self._layers = torch.nn.Sequential(*[deepcopy(self._layer) for i in range(self._layers_per_interaction)])\n",
    "        self._self_interaction_layers =  torch.nn.Sequential(*[deepcopy(self._layers) for i in range(self._self_interaction)])\n",
    "        self._neighbor_interaction_layers =  torch.nn.Sequential(*[deepcopy(self._layers) for i in range(self._neighbor_interaction)])\n",
    "        \n",
    "        self._output_layer = torch.nn.Linear(self._feature_size, 1, dtype=dtype, device=device)\n",
    "        self._self_interaction_linear_layers =  torch.nn.Sequential(*[deepcopy(self._output_layer) for i in range(self._self_interaction)])\n",
    "        self._neighbor_interaction_layers =  torch.nn.Sequential(*[deepcopy(self._output_layer) for i in range(self._neighbor_interaction)])\n",
    "\n",
    "    def forward(self,\n",
    "            positions: torch.Tensor,\n",
    "            cells: torch.Tensor,\n",
    "            species: torch.Tensor,\n",
    "            cell_shifts: torch.Tensor,\n",
    "            centers: torch.Tensor,\n",
    "            pairs: torch.Tensor,\n",
    "            structure_centers: torch.Tensor,\n",
    "            structure_pairs: torch.Tensor,\n",
    "            structure_offsets: torch.Tensor\n",
    "        ):\n",
    "\n",
    "        cartesian_vectors = get_cartesian_vectors(\n",
    "            positions, cells, species, cell_shifts, centers, pairs, structure_centers, structure_pairs, structure_offsets)\n",
    "\n",
    "        # add offset to pair_i to make center index unique\n",
    "        #pair_i = labels[:, 1]\n",
    "        #structure_each_center = torch.cat([torch.tensor(sum(pair_i == i)*[i], dtype=torch.int64) \n",
    "        #                                                 for i in range(len(structure_offsets))])\n",
    "        #pair_i = torch.cat([pair_i[pair_i == i] + structure_offsets[i] for i in range(len(structure_offsets))])\n",
    "        #pair_i = structure_pairs\n",
    "        #unique_centers = torch.tensor([structure_centers[i] + structure_offsets[i] for i in range(len(structure_offsets))])\n",
    "\n",
    "        # add structure offset to  make indices unique over structures\n",
    "        centers_i = structure_offsets[structure_centers] + centers\n",
    "        pairs_i = structure_offsets[structure_pairs] + pairs[:, 0]\n",
    "        #assert torch.allclose(torch.unique(centers_i), centers_i)\n",
    "        #assert torch.allclose(torch.arange(len(centers_i)), centers_i)\n",
    "            \n",
    "        r = torch.sqrt(\n",
    "            (cartesian_vectors**2)\n",
    "            .sum(dim=-1)\n",
    "        )\n",
    "        \n",
    "        embedding = self._embedding(r)\n",
    "\n",
    "        pair_x = self._layers(embedding)\n",
    "        # this pair_E_x is splined\n",
    "        pair_E = self._output_layer(pair_x)\n",
    "        #torch.zeros(len(centers_i), embedding.shape[-1], dtype=embedding.dtype)\n",
    "\n",
    "        for i in range(len(self._self_interaction_layers)):\n",
    "            # central representation becomes weight\n",
    "            center_w = torch.zeros(len(centers_i), pair_E.shape[-1], dtype=pair_E.dtype, device=pair_E.device)\n",
    "            center_w.index_reduce_(0, pairs_i, pair_E, reduce=\"mean\")\n",
    "            # new representation is computed\n",
    "            pair_x = self._self_interaction_layers[i](embedding)\n",
    "            pair_E = self._self_interaction_linear_layers[i](pair_x)\n",
    "            # multiply pair energies with weights\n",
    "            pair_E = torch.cat([pair_E[pairs_i==i] * center_w[i] for i in range(len(centers_i))]) # double check cat, might be stack\n",
    "            #  pair_E = pair_E * center_w[pairs_i] ? can replace above?\n",
    "\n",
    "            #weights_center.index_add_(0, pair_x, weights_pair)\n",
    "            #weights_center = torch.zeros(len(centers_i), embedding.shape[-1], dtype=embedding.dtype)\n",
    "            #weights_center.index_add_(0, structure_pairs, weights_pair)\n",
    "            #\n",
    "            #pair_x = self._self_interaction_layers[i](embedding)\n",
    "            ## weights are computed from previous by suming center representation\n",
    "            #weights_pair = self._self_interaction_liner_layers[i](pair_x)\n",
    "            #pair_x *= weights_center\n",
    "            #weights_center = torch.zeros(len(centers_i), embedding.shape[-1], dtype=embedding.dtype)\n",
    "            #weights_center.index_add_(0, structure_pairs, weights_pair)\n",
    "            #\n",
    "            ##pair_x = self._self_interaction_liner_layers[i](pair_x)\n",
    "            ##center_x = torch.zeros(len(centers_i), embedding.shape[-1], dtype=embedding.dtype)\n",
    "            ##center_x.index_add_(0, structure_pairs, pair_x)\n",
    "            #\n",
    "            ##pair_x = torch.tensor([embedding[structure_pairs[structure_pairs==i]] * center_x[i] for i in range(len(center_x))])\n",
    "            #pair_x = self._self_interaction_layers[i](embedding)\n",
    "            #pair_x *= weights_center\n",
    "            ##center_x = torch.zeros(len(centers_i), embedding.shape[-1], dtype=embedding.dtype)\n",
    "            ##center_x.index_add_(0, structure_pairs, pair_x)\n",
    "            ##center_x = center_x\n",
    "        \n",
    "        for i in range(len(self._neighbor_interaction_layers)):\n",
    "            center_w = torch.zeros(len(centers_i), pair_E.shape[-1], dtype=pair_E.dtype, device=pair_E.device)\n",
    "            center_w.index_reduce_(0, pairs_i, pair_E, reduce=\"mean\")\n",
    "            \n",
    "            # new representation is computed\n",
    "            pair_x = self._neighbor_interaction_layers[i](embedding)\n",
    "            pair_E = self._neighbor_interaction_linear_layers[i](pair_x)\n",
    "            # multiply pair energies with weights\n",
    "            #pair_E = pair_E * center_w[pair_j]\n",
    "            #pair_E = torch.cat([pair_E[pairs_i==i] * center_w[pair_j] for j in range(len(pairs_j))])\n",
    "            \n",
    "        \n",
    "        center_E = torch.zeros(len(centers_i), pair_E.shape[-1], dtype=pair_E.dtype, device=pair_E.device)\n",
    "        center_E.index_add_(0, pairs_i, pair_E)\n",
    "        #center_E.index_reduce_(0, pairs_i, pair_E, \"mean\")\n",
    "\n",
    "        # this index_add_ is reproduced in the MD code\n",
    "        #center_x = torch.zeros(len(centers_i), embedding.shape[-1], dtype=embedding.dtype)\n",
    "        #center_x.index_add_(0, structure_pairs, pair_x)\n",
    "\n",
    "        y = torch.zeros(len(structure_offsets), center_E.shape[-1], dtype=center_E.dtype, device=center_E.device)\n",
    "        y.index_reduce_(0, structure_centers, center_E, reduce=\"mean\")\n",
    "        y = y.squeeze()\n",
    "        #y = self._output_layer(structure_x)\n",
    "        #y = torch.sum(y, dim=-1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0bddb87-48f1-4419-8725-edbea6e80a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_275690/3148346043.py:114: UserWarning: index_reduce() is in beta and the API may change at any time. (Triggered internally at ../aten/src/ATen/native/TensorAdvancedIndexing.cpp:1138.)\n",
      "  y.index_reduce_(0, structure_centers, center_E, reduce=\"mean\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2920, 0.2637, 0.2637, 0.2731, 0.2919, 0.2826, 0.3013, 0.3014,\n",
       "        0.3201, 0.3107, 0.2919, 0.2638, 0.2920, 0.3296, 0.3108, 0.3014, 0.3108,\n",
       "        0.3014, 0.2825, 0.3013, 0.3202, 0.3296, 0.3296, 0.3108, 0.3202, 0.2824,\n",
       "        0.2825, 0.3107, 0.3295, 0.3297, 0.3108, 0.3107, 0.3108, 0.3108, 0.3203,\n",
       "        0.3202, 0.3108, 0.3109, 0.3202, 0.3296, 0.3295, 0.3295, 0.3201, 0.3390,\n",
       "        0.3109, 0.2825, 0.3107, 0.3296, 0.3296, 0.3013, 0.3295, 0.3294, 0.3296,\n",
       "        0.3295, 0.3108, 0.3107, 0.3201, 0.3014, 0.3013, 0.3201, 0.3201, 0.3202,\n",
       "        0.3296, 0.3202, 0.3295, 0.3296, 0.3202, 0.3108, 0.3296, 0.3107, 0.3295,\n",
       "        0.3295, 0.3295, 0.3201, 0.3296, 0.3295, 0.3296, 0.3202, 0.3483, 0.3108,\n",
       "        0.3389, 0.3295, 0.3013, 0.3390, 0.3108, 0.3202, 0.3296, 0.3296, 0.3295,\n",
       "        0.3390, 0.3295, 0.3296, 0.3295, 0.3296, 0.3201, 0.3578, 0.3390, 0.3295,\n",
       "        0.3295], dtype=torch.float64, grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, collate_fn=collate_nl, shuffle=False)\n",
    "batch = next(iter(dataloader))\n",
    "y = batch.pop('scaled_dressed_energies_per_atom')\n",
    "\n",
    "model = Spliney(cutoff=CUTOFF, layers_per_interaction=5, self_interaction=0, dtype=torch.float64)\n",
    "model.forward(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f03b0d00-e7a5-4776-9562-8180c694d2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.1805e+00, -5.6445e-02,  5.9010e-02, -2.2576e-02,  2.6108e-02,\n",
       "         2.1216e-02, -2.0571e-02, -3.9807e-02, -3.3502e-02,  4.1274e-02,\n",
       "        -1.2426e-02, -7.1245e-02,  2.0948e-02, -2.8432e-02, -8.6263e-02,\n",
       "        -4.4372e-02, -8.5924e-02, -5.0947e-02, -7.0792e-03,  5.8478e-02,\n",
       "         2.7536e-02, -4.0116e-04, -8.2182e-03, -1.9296e-02, -7.8347e-02,\n",
       "        -4.3808e-02,  6.3198e-03,  1.3588e-02,  1.3791e-02, -1.7708e-02,\n",
       "        -7.5597e-02,  5.3542e-02,  4.8868e-02,  7.0688e-03, -5.2292e-03,\n",
       "        -8.1301e-02, -4.6776e-02, -5.0999e-02, -5.3947e-02, -7.1742e-03,\n",
       "        -7.2100e-02, -5.6128e-02, -6.1315e-02, -2.1426e-02,  1.4245e-01,\n",
       "         5.8756e-02,  3.0088e-02, -4.4821e-02, -1.5990e-02,  3.9696e-02,\n",
       "         3.3556e-02,  3.8578e-03, -3.6109e-02,  2.8281e-02,  1.0813e-02,\n",
       "         1.6176e-02, -1.0802e-03,  2.2467e-02,  6.0416e-02, -1.6645e-02,\n",
       "         2.7354e-02,  8.8307e-02,  5.0115e-02, -1.3700e-02, -3.3192e-03,\n",
       "         1.4779e-02, -1.7340e-02, -1.1700e-02, -5.0512e-03, -5.0031e-02,\n",
       "         2.1344e-02,  1.3345e-01,  1.0779e-01, -5.7552e-03, -4.8395e-02,\n",
       "         5.9340e-02,  1.3203e-01,  4.3481e-02, -5.8115e-02,  3.3991e-01,\n",
       "        -1.2960e-02,  1.9390e-01,  5.4426e-02,  1.3204e-01,  1.8382e-01,\n",
       "         1.0490e-01,  2.5584e-02,  1.3960e-01, -2.5562e-02,  1.8932e-01,\n",
       "         2.3959e-01,  1.4422e-01,  1.9184e-02,  3.9410e-01,  4.8408e-03,\n",
       "         1.0327e-01,  2.2346e-01,  1.5134e-01,  6.9178e-02, -2.3089e-02],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6d69eeb-dc92-42a7-a59e-8616a12a1c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['positions', 'species', 'cell', 'centers', 'pairs', 'cell_shifts', 'scaled_dressed_energies_per_atom'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19947a76-1c5b-4ac5-a5b5-93d304b3c699",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a484826-0960-4700-9bb5-823e087ed649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.set_default_device(\"cuda:0\")\n",
    "DTYPE = torch.float32\n",
    "DEVICE = \"cpu\"\n",
    "collate_nl_and_move = functools.partial(collate_nl, dtype=DTYPE, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561501d-221e-4d77-a9b1-40311ec5b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataset = InMemoryDataset(frames,\n",
    "                          [TransformerNeighborList(cutoff=CUTOFF, dtype=DTYPE),\n",
    "                           TransformerProperty(\"scaled_dressed_energies_per_atom\",\n",
    "                                               get_dressed_energy_per_atom, dtype=DTYPE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86bd7887-48a1-436d-afd8-3f376d94fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(big_dataset, [3/6, 1/6, 2/6], generator=generator)\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=100, collate_fn=collate_nl_and_move, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=100, collate_fn=collate_nl_and_move, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=100, collate_fn=collate_nl_and_move, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "def loss_fn(pred, true):\n",
    "    return torch.mean((pred - true)**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "550a08e1-ddd9-4243-a62c-1d191b491e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Spliney(cutoff=CUTOFF, feature_size=128, layers_per_interaction=5, self_interaction=1, dtype=DTYPE, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206d38d-f6ed-497d-b8a6-2933940286e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71283 0.56078\n",
      "0.70002 0.58091\n",
      "0.69301 0.65164\n",
      "0.69601 0.55963\n",
      "0.72074 0.60807\n",
      "0.69494 0.55901\n",
      "0.72730 0.59368\n",
      "0.68662 0.59040\n",
      "0.70815 0.56039\n",
      "0.70836 0.58649\n",
      "0.70685 0.58131\n",
      "0.70205 0.59194\n",
      "0.69366 0.58277\n",
      "0.69269 0.61650\n",
      "0.69985 0.56070\n",
      "0.69376 0.56015\n",
      "0.70728 0.56012\n",
      "0.70299 0.55954\n",
      "0.69473 0.56019\n",
      "0.68608 0.56025\n",
      "0.70707 0.59317\n",
      "0.69331 0.55985\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 50\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch_index in range(n_epoch):\n",
    "    train_loss = 0.\n",
    "    for batch in train_dataloader:\n",
    "        # Every data instance is an input + label pair\n",
    "        y = batch.pop('scaled_dressed_energies_per_atom')\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        y_pred = model.forward(**batch)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "    train_loss = np.sqrt(train_loss / len(train_dataloader)) # loss per batch\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    test_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            # Gather data and report\n",
    "            y = batch.pop('scaled_dressed_energies_per_atom')\n",
    "            y_pred = model.forward(**batch)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            test_loss += loss.item()        \n",
    "    test_loss = np.sqrt(test_loss / len(test_dataloader)) # loss per batch\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print(\"{0:0.5f}\".format(train_loss), \"{0:0.5f}\".format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68fd804-6e53-4661-b04f-74cff7760bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(train_loss)\n",
    "plt.loglog(test_loss)\n",
    "plt.savefig(\"training_results.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e7ecf-05a0-4fe1-a27f-ec69af7ab430",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### RadialSpectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d0874ec-519a-4a25-aad1-1e1e2c0004c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadialSpectrum(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                cutoff: float,\n",
    "                feature_size: int = 128,\n",
    "                layers_per_interaction = 6,\n",
    "                self_interaction: int = 5,\n",
    "                neighbor_interaction: int = 2,\n",
    "                dtype = None,\n",
    "                device = None):\n",
    "        super().__init__()\n",
    "        self._feature_size = feature_size\n",
    "        self._layers_per_interaction = layers_per_interaction\n",
    "        self._self_interaction = self_interaction\n",
    "        self._neighbor_interaction = neighbor_interaction\n",
    "\n",
    "        self._embedding = torch.nn.Sequential(\n",
    "                            GaussianRBF(n_rbf=feature_size, cutoff=cutoff),\n",
    "                            CosineCutoff(cutoff) # maybe its this guy!\n",
    "        )\n",
    "        self._embedding.to(device=device, dtype=dtype)\n",
    "        self._layer = torch.nn.Sequential(\n",
    "                        torch.nn.Linear(self._feature_size, self._feature_size, dtype=dtype, device=device),\n",
    "                        torch.nn.SiLU())\n",
    "        self._layers = torch.nn.Sequential(*[deepcopy(self._layer) for i in range(self._layers_per_interaction)])\n",
    "        self._self_interaction_layers =  torch.nn.Sequential(*[deepcopy(self._layers) for i in range(self._self_interaction)])\n",
    "        #self._neighbor_interaction_layers =  torch.nn.Sequential(*[deepcopy(self._layers) for i in range(self._neighbor_interaction)])\n",
    "        self._output_layer = torch.nn.Linear(self._feature_size, 1, dtype=dtype, device=device)\n",
    "        self._self_interaction_linear_layers =  torch.nn.Sequential(*[deepcopy(self._output_layer) for i in range(self._self_interaction)])\n",
    "\n",
    "    def forward_dist(self,\n",
    "            positions: torch.Tensor,\n",
    "            cells: torch.Tensor,\n",
    "            species: torch.Tensor,\n",
    "            cell_shifts: torch.Tensor,\n",
    "            centers: torch.Tensor,\n",
    "            pairs: torch.Tensor,\n",
    "            structure_centers: torch.Tensor,\n",
    "            structure_pairs: torch.Tensor,\n",
    "            structure_offsets: torch.Tensor\n",
    "        ):\n",
    "\n",
    "        cartesian_vectors = get_cartesian_vectors(\n",
    "            positions, cells, species, cell_shifts, centers, pairs, structure_centers, structure_pairs, structure_offsets)\n",
    "\n",
    "\n",
    "        # add structure offset to  make indices unique over structures\n",
    "        centers_i = structure_offsets[structure_centers] + centers\n",
    "        pairs_i = structure_offsets[structure_pairs] + pairs[:, 0]\n",
    "            \n",
    "        r = torch.sqrt(\n",
    "            (cartesian_vectors**2)\n",
    "            .sum(dim=-1)\n",
    "        )\n",
    "        return r\n",
    "    \n",
    "    def forward_embedding(self,\n",
    "            positions: torch.Tensor,\n",
    "            cells: torch.Tensor,\n",
    "            species: torch.Tensor,\n",
    "            cell_shifts: torch.Tensor,\n",
    "            centers: torch.Tensor,\n",
    "            pairs: torch.Tensor,\n",
    "            structure_centers: torch.Tensor,\n",
    "            structure_pairs: torch.Tensor,\n",
    "            structure_offsets: torch.Tensor\n",
    "        ):\n",
    "\n",
    "        cartesian_vectors = get_cartesian_vectors(\n",
    "            positions, cells, species, cell_shifts, centers, pairs, structure_centers, structure_pairs, structure_offsets)\n",
    "\n",
    "\n",
    "        # add structure offset to  make indices unique over structures\n",
    "        centers_i = structure_offsets[structure_centers] + centers\n",
    "        pairs_i = structure_offsets[structure_pairs] + pairs[:, 0]\n",
    "            \n",
    "        r = torch.sqrt(\n",
    "            (cartesian_vectors**2)\n",
    "            .sum(dim=-1)\n",
    "        )\n",
    "        return self._embedding(r)\n",
    "\n",
    "\n",
    "    def forward_repr(self,\n",
    "            positions: torch.Tensor,\n",
    "            cells: torch.Tensor,\n",
    "            species: torch.Tensor,\n",
    "            cell_shifts: torch.Tensor,\n",
    "            centers: torch.Tensor,\n",
    "            pairs: torch.Tensor,\n",
    "            structure_centers: torch.Tensor,\n",
    "            structure_pairs: torch.Tensor,\n",
    "            structure_offsets: torch.Tensor\n",
    "        ):\n",
    "\n",
    "        cartesian_vectors = get_cartesian_vectors(\n",
    "            positions, cells, species, cell_shifts, centers, pairs, structure_centers, structure_pairs, structure_offsets)\n",
    "\n",
    "\n",
    "        # add structure offset to  make indices unique over structures\n",
    "        centers_i = structure_offsets[structure_centers] + centers\n",
    "        pairs_i = structure_offsets[structure_pairs] + pairs[:, 0]\n",
    "            \n",
    "        r = torch.sqrt(\n",
    "            (cartesian_vectors**2)\n",
    "            .sum(dim=-1)\n",
    "        )\n",
    "        embedding = self._embedding(r)\n",
    "        center_x = torch.zeros(len(centers_i), embedding.shape[-1], dtype=embedding.dtype, device=embedding.device)\n",
    "        center_x.index_add_(0, pairs_i, embedding)\n",
    "\n",
    "        structure_x = torch.zeros(len(structure_offsets), center_x.shape[-1], dtype=center_x.dtype, device=center_x.device)\n",
    "        structure_x.index_reduce_(0, structure_centers, center_x, reduce=\"mean\")\n",
    "\n",
    "        return structure_x\n",
    "        \n",
    "    def forward(self,\n",
    "            positions: torch.Tensor,\n",
    "            cells: torch.Tensor,\n",
    "            species: torch.Tensor,\n",
    "            cell_shifts: torch.Tensor,\n",
    "            centers: torch.Tensor,\n",
    "            pairs: torch.Tensor,\n",
    "            structure_centers: torch.Tensor,\n",
    "            structure_pairs: torch.Tensor,\n",
    "            structure_offsets: torch.Tensor\n",
    "        ):\n",
    "\n",
    "        cartesian_vectors = get_cartesian_vectors(\n",
    "            positions, cells, species, cell_shifts, centers, pairs, structure_centers, structure_pairs, structure_offsets)\n",
    "\n",
    "\n",
    "        # add structure offset to  make indices unique over structures\n",
    "        centers_i = structure_offsets[structure_centers] + centers\n",
    "        pairs_i = structure_offsets[structure_pairs] + pairs[:, 0]\n",
    "            \n",
    "        r = torch.sqrt(\n",
    "            (cartesian_vectors**2)\n",
    "            .sum(dim=-1)\n",
    "        )\n",
    "        \n",
    "        embedding = self._embedding(r)\n",
    "        center_x = torch.zeros(len(centers_i), embedding.shape[-1], dtype=embedding.dtype, device=embedding.device)\n",
    "        center_x.index_add_(0, pairs_i, embedding)\n",
    "        center_x = self._layers(center_x)\n",
    "        center_E = self._output_layer(center_x)\n",
    "        y = torch.zeros(len(structure_offsets), center_E.shape[-1], dtype=center_E.dtype, device=center_E.device)\n",
    "        y.index_reduce_(0, structure_centers, center_E, reduce=\"mean\")\n",
    "        y = y.squeeze()\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec367ff9-1dba-44ec-a4fa-5e06c7f1185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rs = RadialSpectrum(cutoff=CUTOFF, feature_size=128, layers_per_interaction=5, self_interaction=0, neighbor_interaction=0, dtype=DTYPE, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6edc86be-0f8b-488d-aa10-7cc985e71182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22509 0.24378\n",
      "0.21789 0.25481\n",
      "0.22126 0.25055\n",
      "0.22873 0.24548\n",
      "0.24349 0.24756\n",
      "0.23188 0.24447\n",
      "0.21771 0.24884\n",
      "0.24542 0.24793\n",
      "0.22396 0.25164\n",
      "0.23339 0.25480\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m test_dataloader:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# Gather data and report\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     y \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaled_dressed_energies_per_atom\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_rs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n\u001b[1;32m     34\u001b[0m     test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()        \n",
      "Cell \u001b[0;32mIn[33], line 141\u001b[0m, in \u001b[0;36mRadialSpectrum.forward\u001b[0;34m(self, positions, cells, species, cell_shifts, centers, pairs, structure_centers, structure_pairs, structure_offsets)\u001b[0m\n\u001b[1;32m    134\u001b[0m pairs_i \u001b[38;5;241m=\u001b[39m structure_offsets[structure_pairs] \u001b[38;5;241m+\u001b[39m pairs[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    136\u001b[0m r \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\n\u001b[1;32m    137\u001b[0m     (cartesian_vectors\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    139\u001b[0m )\n\u001b[0;32m--> 141\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m center_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(centers_i), embedding\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39membedding\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39membedding\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    143\u001b[0m center_x\u001b[38;5;241m.\u001b[39mindex_add_(\u001b[38;5;241m0\u001b[39m, pairs_i, embedding)\n",
      "File \u001b[0;32m~/miniconda3/envs/splinable-nn/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/splinable-nn/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/splinable-nn/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/splinable-nn/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/splinable-nn/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 79\u001b[0m, in \u001b[0;36mGaussianRBF.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgaussian_rbf\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidths\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 84\u001b[0m, in \u001b[0;36mgaussian_rbf\u001b[0;34m(inputs, offsets, widths)\u001b[0m\n\u001b[1;32m     82\u001b[0m coeff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mpow(widths, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     83\u001b[0m diff \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m-\u001b[39m offsets\n\u001b[0;32m---> 84\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoeff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epoch = 100\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch_index in range(n_epoch):\n",
    "    train_loss = 0.\n",
    "    for batch in train_dataloader:\n",
    "        # Every data instance is an input + label pair\n",
    "        y = batch.pop('scaled_dressed_energies_per_atom')\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        y_pred = model_rs.forward(**batch)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "    train_loss = np.sqrt(train_loss / len(train_dataloader)) # loss per batch\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    test_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            # Gather data and report\n",
    "            y = batch.pop('scaled_dressed_energies_per_atom')\n",
    "            y_pred = model_rs.forward(**batch)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            test_loss += loss.item()        \n",
    "    test_loss = np.sqrt(test_loss / len(test_dataloader)) # loss per batch\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print(\"{0:0.5f}\".format(train_loss), \"{0:0.5f}\".format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07115b2a-fd46-43b6-9e43-a4ad773ad354",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rs = RadialSpectrum(cutoff=CUTOFF, feature_size=128, layers_per_interaction=0, self_interaction=0, neighbor_interaction=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d4ef6-12c5-4960-bc26-e48a174a3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataloader = torch.utils.data.DataLoader(big_dataset, batch_size=100, collate_fn=collate_nl, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a138d295-4ac6-4c37-af22-cedd57cc3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_repr = []\n",
    "ys = []\n",
    "for batch in big_dataloader:\n",
    "    ys.append(batch.pop('scaled_dressed_energies_per_atom'))\n",
    "\n",
    "    # Make predictions for this batch\n",
    "    x = model_rs.forward_repr(**batch)\n",
    "    rs_repr.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8a240b-831d-4f3d-81df-81f7f2533c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.cat(rs_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e23de2-c221-42b3-8b4f-3998df5a2537",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958bce13-762b-4cd3-bf31-7a748e868035",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dc8803-ac46-43fb-8820-8dcd66ee2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.linalg.lstsq(X, y).solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d424af-2b5c-42ee-a245-61a4f7d2a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(X@w, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90fea1-4c98-47e9-b760-772b12138a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in torch.randint(len(X), size=(10,)):\n",
    "    plt.plot(X[i].detach().numpy())\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a9915-af16-451b-8873-664e347aa256",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_embedding = []\n",
    "ys = []\n",
    "for batch in whole_dataloader:\n",
    "    ys.append(batch.pop('scaled_dressed_energies_per_atom'))\n",
    "\n",
    "    # Make predictions for this batch\n",
    "    x = model_rs.forward_embedding(**batch)\n",
    "    rs_embedding.append(x)\n",
    "X = torch.cat(rs_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2234d710-36dc-49cc-ab18-7a4491deba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in torch.randint(len(X), size=(10,)):\n",
    "    plt.plot(X[i].detach().numpy())\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642dcad-968b-4059-92bc-2aa4b2da4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_embedding = torch.nn.Sequential(\n",
    "                    GaussianRBF(n_rbf=128, cutoff=CUTOFF),\n",
    "                    #CosineCutoff(CUTOFF)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa37e2-7def-4c11-92e5-b3dd3d9a5f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(linear_embedding(torch.linspace(0,5,10)).detach().numpy().T) \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0466885-e51e-4620-84a1-183cdc3766a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(linear_embedding(torch.linspace(0,5,10)).detach().numpy().sum(0)) \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5db177-dea4-4219-853a-ba91ac1f7b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_embedding(torch.linspace(0,5,100)).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
